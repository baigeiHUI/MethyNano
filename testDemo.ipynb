{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "CKPT_PATH = r\"models\\singletype\\CHG.pth\"  \n",
    "TEST_CSV  = r\"data\\test_CHH.csv\"  \n",
    "\n",
    "BATCH_SIZE = 512\n",
    "NUM_WORKERS = 0\n",
    "SIG_SCALAR_MODE = \"none\"   \n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from scripts.dataLoader import (\n",
    "    load_dataset, make_data, MyDataSet, encode_seq_13mer\n",
    ")\n",
    "from moduls import MethyNano\n",
    "\n",
    "def _nz(x: torch.Tensor) -> torch.Tensor:\n",
    "  \n",
    "    return torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "def _collate_cls_13mer(batch):\n",
    " \n",
    "    seq_ids, sig, stats, labels = [], [], [], []\n",
    "    for s, n, y in batch:\n",
    "        n = torch.as_tensor(n, dtype=torch.float32)  # [13,103]\n",
    "\n",
    "        st = n[:, :3]\n",
    "        sg = n[:, 3:]\n",
    "\n",
    "        if SIG_SCALAR_MODE != \"none\":\n",
    "            if SIG_SCALAR_MODE == \"first\":\n",
    "                v = sg[:, 0]\n",
    "            elif SIG_SCALAR_MODE == \"center\":\n",
    "                v = sg[:, 50]\n",
    "            elif SIG_SCALAR_MODE == \"mean\":\n",
    "                v = sg.mean(dim=-1)\n",
    "            else:\n",
    "                v = sg.mean(dim=-1)\n",
    "            sg = v.unsqueeze(-1).expand(-1, sg.size(-1))  # [13] -> [13,100]\n",
    "\n",
    "        st = _nz(st)\n",
    "        sg = _nz(sg)\n",
    "\n",
    "        seq_ids.append(torch.tensor(encode_seq_13mer(s), dtype=torch.long))\n",
    "        stats.append(st)\n",
    "        sig.append(sg)\n",
    "        labels.append(torch.tensor(int(y), dtype=torch.long))\n",
    "\n",
    "    seq_ids = torch.stack(seq_ids, 0)   # [B,13]\n",
    "    stats   = torch.stack(stats,   0)   # [B,13,3]\n",
    "    sig     = torch.stack(sig,     0)   # [B,13,100]\n",
    "    labels  = torch.stack(labels,  0)   # [B]\n",
    "    return seq_ids, sig, stats, labels\n",
    "\n",
    "def build_test_loader(test_csv, batch_size=256, num_workers=4):\n",
    "  \n",
    "    testData = load_dataset(test_csv, feature_mode=\"both\", mask=-1)\n",
    "    seq, nano, label = make_data(testData)\n",
    "    ds = MyDataSet(seq, nano, label)\n",
    "    loader = DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=(num_workers > 0),\n",
    "        collate_fn=_collate_cls_13mer,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    return loader, seq, label \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = MethyNano(\n",
    "    with_projection=False,\n",
    "    with_classification=True,\n",
    "    dimension=256,\n",
    "    n_heads=8,\n",
    "    dropout=0.1,\n",
    "    base_sig=160,\n",
    ").to(device)\n",
    "\n",
    "print(\"Loading checkpoint from:\", CKPT_PATH)\n",
    "ckpt = torch.load(CKPT_PATH, map_location=\"cpu\")\n",
    "state = ckpt.get(\"model\", ckpt)  \n",
    "missing, unexpected = model.load_state_dict(state, strict=False)\n",
    "print(f\"missing keys: {len(missing)}, unexpected keys: {len(unexpected)}\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_loader, test_seq_list, test_label_tensor = build_test_loader(\n",
    "    TEST_CSV, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS\n",
    ")\n",
    "\n",
    "all_probs = []\n",
    "all_logits = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(test_loader, desc=\"Predict\", dynamic_ncols=True)\n",
    "    for seq_ids, sig, stats, labels in pbar:\n",
    "        sig = _nz(sig).to(device)\n",
    "        stats = _nz(stats).to(device)\n",
    "        seq_ids = seq_ids.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        out = model(sig, seq_ids, stats)\n",
    "        logits = out[\"logits\"]                            # [B,2]\n",
    "        probs = F.softmax(logits, dim=-1)[:, 1]       \n",
    "\n",
    "        all_logits.append(logits.cpu())\n",
    "        all_probs.append(probs.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "\n",
    "\n",
    "all_logits = torch.cat(all_logits, dim=0)    # [N,2]\n",
    "all_probs  = torch.cat(all_probs,  dim=0)    # [N]\n",
    "all_labels = torch.cat(all_labels, dim=0)    # [N]\n",
    "\n",
    "preds = (all_probs >= 0.5).long()           \n",
    "\n",
    "print(\"Total samples:\", all_labels.numel())\n",
    "print(\"Positive ratio (true):\", float((all_labels == 1).float().mean()))\n",
    "print(\"Positive ratio (pred):\", float((preds == 1).float().mean()))\n",
    "\n",
    "\n",
    "acc = float((preds == all_labels).float().mean())\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "y_true = all_labels.numpy().astype(int)\n",
    "y_pred = preds.numpy().astype(int)\n",
    "y_score = all_probs.numpy().astype(float)\n",
    "\n",
    "\n",
    "tp = int(((y_pred == 1) & (y_true == 1)).sum())\n",
    "tn = int(((y_pred == 0) & (y_true == 0)).sum())\n",
    "fp = int(((y_pred == 1) & (y_true == 0)).sum())\n",
    "fn = int(((y_pred == 0) & (y_true == 1)).sum())\n",
    "\n",
    "acc = (tp + tn) / max(1, tp + tn + fp + fn)\n",
    "precision = tp / max(1, tp + fp)\n",
    "recall    = tp / max(1, tp + fn)\n",
    "f1        = 2 * precision * recall / max(1e-12, precision + recall)\n",
    "\n",
    "order = np.argsort(-y_score)      \n",
    "y_sorted = y_true[order]\n",
    "\n",
    "P = max(1, (y_true == 1).sum())\n",
    "N = max(1, (y_true == 0).sum())\n",
    "\n",
    "tp_c = np.cumsum(y_sorted == 1)\n",
    "fp_c = np.cumsum(y_sorted == 0)\n",
    "\n",
    "tpr = tp_c / P\n",
    "fpr = fp_c / N\n",
    "\n",
    "auroc = float(np.trapz(\n",
    "    np.concatenate([[0.0], tpr, [1.0]]),\n",
    "    np.concatenate([[0.0], fpr, [1.0]]),\n",
    "))\n",
    "\n",
    "prec_curve = tp_c / np.maximum(1, tp_c + fp_c)\n",
    "rec_curve  = tp_c / P\n",
    "\n",
    "auprc = float(np.trapz(\n",
    "    np.concatenate([[1.0], prec_curve, [prec_curve[-1] if prec_curve.size else 1.0]]),\n",
    "    np.concatenate([[0.0], rec_curve, [1.0]]),\n",
    "))\n",
    "\n",
    "print(\"==== Test metrics ====\")\n",
    "print(f\"ACC    : {acc:.4f}\")\n",
    "print(f\"PREC   : {precision:.4f}\")\n",
    "print(f\"RECALL : {recall:.4f}\")\n",
    "print(f\"F1     : {f1:.4f}\")\n",
    "print(f\"AUROC  : {auroc:.4f}\")\n",
    "print(f\"AUPRC  : {auprc:.4f}\")\n",
    "print(\"======================\")\n",
    "\n",
    "\n",
    "seq_col   = list(test_seq_list)\n",
    "true_col  = all_labels.numpy().astype(int).tolist()\n",
    "pred_col  = preds.numpy().astype(int).tolist()\n",
    "prob_col  = all_probs.numpy().tolist()\n",
    "\n",
    "df_out = pd.DataFrame({\n",
    "    \"seq_13mer\": seq_col,\n",
    "    \"label_true\": true_col,\n",
    "    \"label_pred\": pred_col,\n",
    "    \"prob_pos\": prob_col,\n",
    "})\n",
    "\n",
    "\n",
    "display(df_out.head(10))\n",
    "\n",
    "\n",
    "out_path = \"test_predictions_methynano.csv\"\n",
    "df_out.to_csv(out_path, index=False)\n",
    "print(\"Saved prediction table to:\", out_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
